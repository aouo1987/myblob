[TOC]



## 发布项目

| 项目编号 | 项目名称 | 项目目标 |
| -------- | -------- | -------- |
| xxx         |  xx        |       xx   |

## 发布时间

​	2018-xx-xx

## 发布影响

### 	发布过程影响

​		比如：影响 xx 的日志数据处理和统计,影响时长2分钟,上线完成后正常

### 	业务功能影响

​		比如：业务数据无影响,不变更日志数据结构

## 发布工程以及依赖清单  

| 代码路径 | 模块名称 | 分支 |
| -------- | -------- | ---- |
|          |          |      |

## 发布方案

​	如下：介绍发布中需要执行的脚本
​	1. NDP部署打包jar到指定目标机器(hzadg-iad-mobengine2).
​	2. 登录hzadg-iad-mobengine2 , 进入ndp打包目录,执行提交storm任务脚本：
​		 a) bash adx-engine-realtime-job-deploy.sh 部署adx请求日志预处理任务
​		 b) bash adx-exposure-realtime-job-deploy.sh 部署adx 曝光日志预处理和数据统计任务.
​		 c) bash adx-click-realtime-job-deploy.sh 部署adx 点击日志数据预处理任务.

## 发布步骤

​	 介绍发布过程中，拓扑的启动和停止，数据的维护和保存。

​	 特别注意以下步骤:

​		1) 接入新的kafka Topic , 需提前申请创建。注意storm/druid 对topic双读或双写

​		2) 修改kafka topic consumer ID ，需要保存zookeeper上原有consumer ID的消费进度

​		3) 切换新的topic 或者 kafka水位offset有变更时，需要和storm consumer的消费水位进行比较

​			保证消费水位小于等于kafka的最高水位，否则storm kafka spout无法正常消费。

​			新的topic发布上线后，先在storm ui查看对应的日志和emit的数据,然后在进一步数据核对。

​		 4) 规划好topology，worker,executor的资源并行度配置，保证资源在节点间分布均匀。

​		 5) spout的超时时间和反压阈值(MaxSpoutPending,启动Ack生效) 。

## 验证方案

### 	验收标准 （注意，检查redis缓存,kafka和druid）

​		1）kafka数据和druid数据是否写入成功

​		2）redis数据和druid统计指标的数据是否匹配

​		3）使用druid superset查看整体流量是否正常

### 	验收通过

​	 邮件回复发布完成

### 	验收不通过

​	 回滚

## 回滚方案

  回滚到上一个版本



















